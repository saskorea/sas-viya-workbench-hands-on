{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <center> **손쉽게 따라하는 SAS® Viya® Workbench - Python 사용자편** </center>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **0. Packages 설치**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[주의] saspy 패키지를 설치한 뒤, 창을 다시 열어주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install packages saspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAS 연결\n",
    "import saspy\n",
    "\n",
    "# 데이터 처리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# SAS Viya 알고리즘\n",
    "from sasviya.ml.linear_model import LogisticRegression\n",
    "from sasviya.ml.svm import SVC\n",
    "from sasviya.ml.tree import DecisionTreeClassifier, ForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# 모형 평가\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, auc\n",
    "\n",
    "# 그래프 생성\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**※ saspy 패키지**\n",
    "- 개요\n",
    "    - Python과 SAS 간의 인터페이스를 제공\n",
    "    - Python 프로세스를 SAS 배포에 연결하여 SAS 코드를 실행\n",
    "    - SAS 데이터 세트와 Pandas 데이터 프레임 간 데이터 표현 변환 지원\n",
    "- 필수 조건\n",
    "    - Python3.x 이상\n",
    "    - SAS 9.4 이상\n",
    "    - SAS Viya 3 이상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. SAS 연결 및 Library 할당**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 연결\n",
    "sas = saspy.SASsession()\n",
    "\n",
    "# Library 할당\n",
    "sas.saslib('WRKLIB', path='-라이브러리 경로-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. 데이터 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형식 변환 (sas7bdat → Dataframe) 후 로드\n",
    "churn_parted = sas.sasdata('churn_parted', libref='WRKLIB').to_df()\n",
    "churn_parted.columns = churn_parted.columns.str.upper()\n",
    "churn_parted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. 데이터 분할**  \n",
    "- 학습(Training), 평가(Validation), 검증(Testing) 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 학습용 데이터\n",
    "churn_train = churn_parted[churn_parted['_PARTITION_'] == 0]\n",
    "\n",
    "# (2) 평가용 데이터\n",
    "churn_valid = churn_parted[churn_parted['_PARTITION_'] == 1]\n",
    "\n",
    "# (3) 검증용 데이터\n",
    "churn_test  = churn_parted[churn_parted['_PARTITION_'] == 2]\n",
    "\n",
    "print(\"## Table Size (4:3:3)\")\n",
    "print(f\" - Train Set: {churn_train.shape[0]:,}\")\n",
    "print(f\" - Valid Set: {churn_valid.shape[0]:,}\")\n",
    "print(f\" -  Test Set: {churn_test.shape[0]:,}\")\n",
    "print()\n",
    "print(\"## Target Rate\")\n",
    "print(f\" - Train Set: {churn_train['CHURN'].mean():.3f}\")\n",
    "print(f\" - Valid Set: {churn_valid['CHURN'].mean():.3f}\")\n",
    "print(f\" -  Test Set: {churn_test['CHURN'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. 변수 분리**  \n",
    "- 입력변수, 타겟변수 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 전체\n",
    "full_X = churn_train.drop(columns=['ID','CHURN','_PARTITION_'], errors='ignore')\n",
    "full_y = churn_train['CHURN']\n",
    "\n",
    "# (2) 학습용\n",
    "X_train = churn_train.drop(columns=['ID','CHURN','_PARTITION_'], errors='ignore')\n",
    "y_train = churn_train['CHURN']\n",
    "\n",
    "# (3) 평가용\n",
    "X_valid = churn_valid.drop(columns=['ID','CHURN','_PARTITION_'], errors='ignore')\n",
    "y_valid = churn_valid['CHURN']\n",
    "\n",
    "# (4) 검증용\n",
    "X_test = churn_test.drop(columns=['ID','CHURN','_PARTITION_'], errors='ignore')\n",
    "y_test = churn_test['CHURN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. 모형 적합**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1. 의사결정나무**  \n",
    "**(1) 모형 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion = \"chisquare\",\n",
    "                            max_depth = 10,\n",
    "                            ccp_alpha = 0)\n",
    "\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 주요 Hyper Parameters**\n",
    "\n",
    "- **criterion**: `{“chaid”, “chisquare”, “entropy|gain”, “igr|gainratio”, “gini”}`  \n",
    "  각 트리 노드의 분할 기준을 지정합니다.\n",
    "\n",
    "- **max_depth**: `int`  \n",
    "  트리의 최대 깊이를 지정합니다.\n",
    "\n",
    "- **ccp_alpha**: `float`  \n",
    "  회귀 트리의 최소 비용 복잡성 가지치기에 사용할 값을 지정합니다.\n",
    "\n",
    "<small> `DecisionTreeClassifier()` 클래스 사용에 대한 자세한 내용은 [**문서**](https://go.documentation.sas.com/doc/en/workbenchcdc/v_001/vwbpymlpg/sasviya-ml-tree-decisiontreeclassifier.htm)를 참고하세요.</small> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2. 랜덤포레스트**  \n",
    "**(1) 모형 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a random forest model\n",
    "forest = ForestClassifier(n_estimators     = 100,\n",
    "                          bootstrap        = 0.6,\n",
    "                          criterion        = \"chisquare\",\n",
    "                          max_depth        = 7,\n",
    "                          min_samples_leaf = 5,\n",
    "                          random_state     = 919)\n",
    "\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 주요 Hyper Parameters**\n",
    "\n",
    "- **n_estimators**: `int`  \n",
    "  생성할 트리의 수를 지정합니다.\n",
    "\n",
    "- **bootstrap**: `float`  \n",
    "  부트스트랩 샘플에 사용할 데이터의 비율을 지정합니다.\n",
    "\n",
    "- **criterion**: `{“chaid”, “chisquare”, “entropy|gain”, “igr|gainratio”, “gini”}`  \n",
    "  각 트리 노드에서 분할의 품질을 측정하는 기준을 지정합니다.\n",
    "\n",
    "- **max_depth**: `int`  \n",
    "  트리의 최대 깊이를 지정합니다.\n",
    "\n",
    "- **min_samples_leaf**: `int`  \n",
    "  각 노드에 최소한으로 있어야 하는 샘플의 수를 지정합니다.\n",
    "\n",
    "- **random_state**: `int`  \n",
    "  난수 생성에 사용할 시드를 지정합니다.\n",
    "\n",
    "<small> `ForestClassifier()` 클래스 사용에 대한 자세한 내용은 [**문서**](https://go.documentation.sas.com/doc/en/workbenchcdc/v_001/vwbpymlpg/sasviya-ml-tree-forestclassifier.htm)를 참고하세요.</small> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.3. 로지스틱회귀**  \n",
    "**(1) 모형 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(tol       = 1e-4,\n",
    "                        solver    = 'lbfgs',\n",
    "                        selection = 'stepwise')\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 주요 Hyper Parameters**\n",
    "\n",
    "- **tol**: `float`  \n",
    "상대적인 기울기 수렴 기준을 지정합니다.\n",
    "\n",
    "- **solver**: `str`  \n",
    "사용할 최적화 알고리즘을 지정합니다. 유효한 옵션은 다음과 같습니다:\n",
    "  - “congra”: 공액 기울기 방법\n",
    "  - “dbldog”: 더블-도그레그 방법\n",
    "  - “lbfgs”: 제한된 메모리 BFGS 해결기\n",
    "  - “newrap”: 라인 탐색 및 리지법을 사용한 뉴턴-랩슨 방법\n",
    "  - “nmsimp”: 넬더-미드 심플렉스 방법\n",
    "  - “nrridg”: 리지법을 사용한 뉴턴-랩슨 방법\n",
    "  - “quanew | duquanew”: 이중 준-뉴턴 최적화\n",
    "\n",
    "- **selection**: `str`  \n",
    "사용할 변수 선택 방법을 지정합니다. 유효한 옵션은 다음과 같습니다:\n",
    "  - “backward”: 후진 선택법\n",
    "  - “forward”: 전진 선택법\n",
    "  - “lasso”: Lasso 방법\n",
    "  - “stepwise”: 단계적 선택법\n",
    "\n",
    "<small> `LogisticRegression()` 클래스 사용에 대한 자세한 내용은 [**문서**](https://go.documentation.sas.com/doc/en/workbenchcdc/v_001/vwbpymlpg/sasviya-ml-linear_model-logisticregression.htm)를 참고하세요.</small> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.4. 지지벡터머신**  \n",
    "**(1) 모형 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a support vector machine classifier\n",
    "svm = SVC(C     = 1.0,\n",
    "          kernel= \"rbf\")\n",
    "\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 주요 Hyper Parameters**\n",
    "\n",
    "- **C**: `float`  \n",
    "비용 정규화 파라미터를 지정합니다.\n",
    "\n",
    "- **kernel**: `{“linear”, “poly”, “polynomial”, “rbf”, “sigmoid”}`  \n",
    "사용할 커널의 유형을 지정합니다.\n",
    "\n",
    "- **random_state**: `int`  \n",
    "난수 생성에 사용할 시드를 지정합니다.\n",
    "\n",
    "<small> `SVC()` 클래스 사용에 대한 자세한 내용은 [**문서**](https://go.documentation.sas.com/doc/en/workbenchcdc/v_001/vwbpymlpg/sasviya-ml-svm-svc.htm)를 참고하세요.</small> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.5. 그레디언트부스팅**  \n",
    "**(1) 모형 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a tree-based gradient boosting\n",
    "gradboost = GradientBoostingClassifier(n_estimators     = 100,\n",
    "                                       max_depth        = 4,\n",
    "                                       min_samples_leaf = 5,\n",
    "                                       learning_rate    = 0.1,\n",
    "                                       subsample        = 0.8,\n",
    "                                       random_state     = 919)\n",
    "\n",
    "gradboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 주요 Hyper Parameters**\n",
    "\n",
    "- **n_estimators**: `int`  \n",
    "  생성할 트리의 수를 지정합니다. 기본값은 100입니다.\n",
    "\n",
    "- **min_samples_leaf**: `int`  \n",
    "  각 노드에 최소한으로 있어야 하는 샘플의 수를 지정합니다. 기본값은 5입니다.\n",
    "\n",
    "- **max_depth**: `int`  \n",
    "  트리의 최대 깊이를 지정합니다. 기본값은 4입니다.\n",
    "\n",
    "- **learning_rate**: `float`  \n",
    "  각 트리의 학습률을 지정합니다. 기본값은 0.1입니다.\n",
    "\n",
    "- **subsample**: `float`  \n",
    "  각 트리를 구축하는 데 사용할 데이터의 비율을 지정합니다. 기본값은 0.5입니다.\n",
    "\n",
    "- **random_state**: `float`  \n",
    "  난수 생성기의 시드를 지정합니다. 기본값은 컴퓨터 시계를 기반으로 한 난수 스트림입니다. 재현 가능한 난수 시퀀스를 원할 경우 0보다 큰 값을 지정합니다.\n",
    "\n",
    "<small> `GradientBoostingClassifier()` 클래스 사용에 대한 자세한 내용은 [**문서**](https://go.documentation.sas.com/doc/en/workbenchcdc/v_001/vwbpymlpg/sasviya-ml-tree-gradientboostingclassifier.htm)를 참고하세요.</small> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. 모형 평가**\n",
    "- 모형 리스트 및 이름 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 리스트 및 이름 정의\n",
    "models = [\n",
    "    (\"Decision Tree\", \"dt\", dt),\n",
    "    (\"Random Forest\", \"rf\", forest),\n",
    "    (\"Logistic Regression\", \"lr\", lr),\n",
    "    (\"Support Vector Machine\", \"svm\", svm),\n",
    "    (\"Gradient Boosting\", \"gbm\", gradboost)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.1. 모형 평가 지표 산출**\n",
    "- **주요 평가 지표**\n",
    "  - **Accuracy(정확도)**: 전체 샘플 중 올바르게 분류된 비율\n",
    "  - **Precision(정밀도)**: 해당 클래스에 대해 양성으로 예측된 것 중 실제 양성의 비율\n",
    "  - **Recall(재현율)**: 실제 양성 중 모델이 양성으로 예측한 비율\n",
    "  - **F1-Score(F1 점수)**: 정밀도와 재현율의 조화 평균 (데이터 불균형 시 유용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장용 리스트\n",
    "metrics = []\n",
    "for name, abbr, model in models:\n",
    "    # 학습용, 평가용, 테스트용 데이터 예측\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # 평가지표 계산\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    accuracy_valid = accuracy_score(y_valid, y_valid_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    precision_train = precision_score(y_train, y_train_pred, average=\"binary\")\n",
    "    precision_valid = precision_score(y_valid, y_valid_pred, average=\"binary\")\n",
    "    precision_test = precision_score(y_test, y_test_pred, average=\"binary\")\n",
    "\n",
    "    recall_train = recall_score(y_train, y_train_pred, average=\"binary\")\n",
    "    recall_valid = recall_score(y_valid, y_valid_pred, average=\"binary\")\n",
    "    recall_test = recall_score(y_test, y_test_pred, average=\"binary\")\n",
    "\n",
    "    f1_train = f1_score(y_train, y_train_pred, average=\"binary\")\n",
    "    f1_valid = f1_score(y_valid, y_valid_pred, average=\"binary\")\n",
    "    f1_test = f1_score(y_test, y_test_pred, average=\"binary\")\n",
    "\n",
    "    # 결과 저장\n",
    "    metrics.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy_Train\": round(accuracy_train, 3),\n",
    "        #\"Accuracy_Valid\": round(accuracy_valid, 3),\n",
    "        \"Accuracy_Test\": round(accuracy_test, 3),\n",
    "        \"Precision_Train\": round(precision_train, 3),\n",
    "        #\"Precision_Valid\": round(precision_valid, 3),\n",
    "        \"Precision_Test\": round(precision_test, 3),\n",
    "        \"Recall_Train\": round(recall_train, 3),\n",
    "        #\"Recall_Valid\": round(recall_valid, 3),\n",
    "        \"Recall_Test\": round(recall_test, 3),\n",
    "        \"F1_Score_Train\": round(f1_train, 3),\n",
    "        #\"F1_Score_Valid\": round(f1_valid, 3),\n",
    "        \"F1_Score_Test\": round(f1_test, 3),\n",
    "    })\n",
    "\n",
    "# 결과 출력\n",
    "metrics_df = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2. ROC 그래프**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC 커브 그리기\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, abbr, model in models:\n",
    "    # 학습용, 평가용, 테스트용 데이터 예측 확률 계산\n",
    "    y_train_pred_proba = model.predict_proba(X_train).iloc[:, 1]\n",
    "    y_valid_pred_proba = model.predict_proba(X_valid).iloc[:, 1]\n",
    "    y_test_pred_proba = model.predict_proba(X_test).iloc[:, 1]\n",
    "\n",
    "    # ROC 커브 계산\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "    auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "    fpr_valid, tpr_valid, _ = roc_curve(y_valid, y_valid_pred_proba)\n",
    "    auc_valid = auc(fpr_valid, tpr_valid)\n",
    "\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_proba)\n",
    "    auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "    # ROC 커브 그리기\n",
    "    plt.plot(fpr_train, tpr_train, label=f\"{name} (Train AUC = {auc_test:.3f})\")\n",
    "    #plt.plot(fpr_valid, tpr_valid, label=f\"{name} (Valid AUC = {auc_valid:.3f})\")\n",
    "    plt.plot(fpr_test, tpr_test, label=f\"{name} (Test AUC = {auc_test:.3f})\")\n",
    "        \n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guessing\")  # 랜덤 분류 기준선\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.3. 향상도 그래프**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift 차트 그리기\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, abbr, model in models:\n",
    "    # 학습용, 평가용, 테스트용 데이터 예측 확률 계산\n",
    "    y_train_pred_proba = model.predict_proba(X_train).iloc[:, 1]\n",
    "    y_valid_pred_proba = model.predict_proba(X_valid).iloc[:, 1]\n",
    "    y_test_pred_proba = model.predict_proba(X_test).iloc[:, 1]\n",
    "\n",
    "    # 전체 양성 비율 계산\n",
    "    train_base_rate = np.mean(y_train)\n",
    "    valid_base_rate = np.mean(y_valid)\n",
    "    test_base_rate = np.mean(y_test)\n",
    "\n",
    "    # 실제 값과 예측 확률을 결합하여 정렬\n",
    "    train_data = np.array(list(zip(y_train, y_train_pred_proba)))\n",
    "    train_data = train_data[train_data[:, 1].argsort()[::-1]]\n",
    "\n",
    "    valid_data = np.array(list(zip(y_valid, y_valid_pred_proba)))\n",
    "    valid_data = valid_data[valid_data[:, 1].argsort()[::-1]]\n",
    "\n",
    "    test_data = np.array(list(zip(y_test, y_test_pred_proba)))\n",
    "    test_data = test_data[test_data[:, 1].argsort()[::-1]]\n",
    "\n",
    "    # 누적 양성 비율 계산\n",
    "    train_cum_positives = np.cumsum(train_data[:, 0])\n",
    "    valid_cum_positives = np.cumsum(valid_data[:, 0])\n",
    "    test_cum_positives = np.cumsum(test_data[:, 0])\n",
    "\n",
    "    # Lift 계산\n",
    "    train_lift = train_cum_positives / (np.arange(1, len(train_cum_positives) + 1)) / train_base_rate\n",
    "    valid_lift = valid_cum_positives / (np.arange(1, len(valid_cum_positives) + 1)) / valid_base_rate\n",
    "    test_lift = test_cum_positives / (np.arange(1, len(test_cum_positives) + 1)) / test_base_rate\n",
    "\n",
    "    # Lift 차트 그리기\n",
    "    plt.plot(np.arange(1, len(train_lift) + 1) / len(train_lift), train_lift, label=f\"{name} (Train Lift)\")\n",
    "    #plt.plot(np.arange(1, len(valid_lift) + 1) / len(valid_lift), valid_lift, label=f\"{name} (Valid Lift)\")\n",
    "    plt.plot(np.arange(1, len(test_lift) + 1) / len(test_lift), test_lift, label=f\"{name} (Test Lift)\")\n",
    "\n",
    "# 랜덤 추측 기준선\n",
    "plt.plot([0, 1], [1, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guessing\")\n",
    "\n",
    "plt.xlabel(\"Percent of Samples\")\n",
    "plt.ylabel(\"Lift\")\n",
    "plt.title(\"Lift Chart Comparison\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. 스코어링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 모델에 대해 예측값과 확률 계산 후 결과 저장\n",
    "for name, abbr, model in models:\n",
    "    y_pred = pd.DataFrame(model.predict(full_X), columns=['I_CHURN'])\n",
    "    y_pred_proba = pd.DataFrame(model.predict_proba(full_X), columns=['P_CHURN0', 'P_CHURN1'])\n",
    "    result = pd.concat([churn_train[['ID', '_PARTITION_']], full_X, full_y, y_pred, y_pred_proba], axis=1)\n",
    "    # 결과 데이터프레임명을 모델 이름으로 설정\n",
    "    globals()[f\"churn_{abbr}_score\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. 결과 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas.df2sd(churn_dt_score, table='churn_py_dtr', libref='WRKLIB')\n",
    "sas.df2sd(churn_rf_score, table='churn_py_rfm', libref='WRKLIB')\n",
    "sas.df2sd(churn_lr_score, table='churn_py_log', libref='WRKLIB')\n",
    "sas.df2sd(churn_svm_score, table='churn_py_svm', libref='WRKLIB')\n",
    "sas.df2sd(churn_gbm_score, table='churn_py_gbm', libref='WRKLIB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8. SAS 연결 종료**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas.endsas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
